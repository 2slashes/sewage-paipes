{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Sewage pAIpes Neural Network Solver**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation details can be found in the main.ipynb section of the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "Load data set from `data/train.csv` and `data/test.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipesDataset(Dataset):\n",
    "    def __init__(self, path: str):\n",
    "        self.path = path\n",
    "        curr_dir = os.getcwd()\n",
    "        data_path = os.path.join(curr_dir, path)\n",
    "        self.df = pd.read_csv(data_path, dtype=str)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        all = self.df.iloc[idx]\n",
    "\n",
    "        state = all.iloc[0]\n",
    "        action = all.iloc[1]\n",
    "\n",
    "        # Create a list, where each entry in the list is an int\n",
    "        # the list as a whole represents the state of the board\n",
    "        state_int_list = [int(x) for x in state]\n",
    "        state_tensor = torch.tensor(state_int_list)\n",
    "\n",
    "        action_int_list = [int(x) for x in action]\n",
    "        action_tensor = torch.tensor(action_int_list)\n",
    "\n",
    "        return (state_tensor, action_tensor)\n",
    "\n",
    "\n",
    "train_pipes = DataLoader(PipesDataset(\"data/train.csv\"), batch_size=64, shuffle=True)\n",
    "test_pipes = DataLoader(PipesDataset(\"data/test.csv\"), batch_size=64, shuffle=True)\n",
    "train_features, train_labels = next(iter(train_pipes))\n",
    "test_features, test_labels = next(iter(test_pipes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for Training\n",
    "\n",
    "- Define network layers\n",
    "- Set device\n",
    "- Set hyper-parameters\n",
    "    - Learning rate\n",
    "    - Batch size\n",
    "    - Loss function\n",
    "    - Optimizer function\n",
    "- Define test/train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipesPredictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "device = (\n",
    "    torch.accelerator.current_accelerator().type\n",
    "    if torch.accelerator.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "n = 4\n",
    "\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "\n",
    "# Initialize the loss function\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model = PipesPredictor(input_size=4*(n**2), hidden_size=128, output_size=n**2).to(device)\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device).float(), y.to(device).float()\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # if batch % 100 == 0:\n",
    "        #     loss, current = loss.item(), batch * batch_size + len(X)\n",
    "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0\n",
    "    total_correct = 0  # total correct label predictions\n",
    "    total_labels = 0   # total number of labels across all samples\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device).float(), y.to(device).float()\n",
    "\n",
    "            logits = model(X)\n",
    "            loss = loss_fn(logits, y)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Convert logits to probabilities and then to a 0/1 mask.\n",
    "            probs = torch.sigmoid(logits)\n",
    "            predicted_mask = (probs >= 0.5).float()\n",
    "\n",
    "            # Count all correct label predictions (element-wise comparison)\n",
    "            total_correct += (predicted_mask == y).float().sum().item()\n",
    "            total_labels += y.numel()  # count of all individual labels\n",
    "\n",
    "    avg_loss = test_loss / num_batches\n",
    "    # Calculate average per-label accuracy as a percentage.\n",
    "    label_accuracy = (total_correct / total_labels) * 100\n",
    "    print(f\"Test Avg loss: {avg_loss:.4f}, Average Label Accuracy: {label_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Train neural network and save it as `model.pth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_pipes, model, loss_fn, optimizer)\n",
    "    test_loop(test_pipes, model, loss_fn)\n",
    "print(\"Done!\")\n",
    "model_file_name = \"model.pth\"\n",
    "curr_dir = os.getcwd()\n",
    "model_file_path = os.path.join(curr_dir, model_file_name)\n",
    "torch.save(model.state_dict(), model_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINE-TUNE ONLY: Train From Existing Model Weight\n",
    "\n",
    "Load an existing model weight from `model.pth` and train from there. Only do this when you are fine-tuning an existing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_name = \"model.pth\"\n",
    "curr_dir = os.getcwd()\n",
    "model_file_path = os.path.join(curr_dir, model_file_name)\n",
    "model.load_state_dict(torch.load(model_file_path, weights_only=True, map_location=device))\n",
    "\n",
    "epochs = 4\n",
    "learning_rate = 1e-5\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_pipes, model, loss_fn, optimizer)\n",
    "    test_loop(test_pipes, model, loss_fn)\n",
    "print(\"Done!\")\n",
    "model_file_name = \"model.pth\"\n",
    "curr_dir = os.getcwd()\n",
    "model_file_path = os.path.join(curr_dir, model_file_name)\n",
    "torch.save(model.state_dict(), model_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve Puzzles Using Model\n",
    "\n",
    "Solves all puzzles from `puzzles.csv` by repeatedly turning the pipe with the highest label, disallowing making the same move on the same state twice, preventing loops.\n",
    "\n",
    "We keep track of **outliers**, which are puzzles that take an unusually large amount of moves to solve. Outliers are currently defined as requiring >70 moves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_move(state, visited):\n",
    "    # convert the state to integers\n",
    "    state_int_list = [int(x) for x in state]\n",
    "    # convert the state to a tensor\n",
    "    state_tensor = torch.tensor(state_int_list).to(device).float()\n",
    "    # get the predicted move from the neural network\n",
    "    prob = model(state_tensor)\n",
    "    results = torch.topk(prob, 16).indices\n",
    "\n",
    "    # Initialize the visited state if we haven't seen it before\n",
    "    if state not in visited:\n",
    "        visited[state] = set()\n",
    "\n",
    "    # Try each of the top moves\n",
    "    result = None\n",
    "    for r in results:\n",
    "        move = int(r)\n",
    "        # Skip if we've already tried this move for this state\n",
    "        if not move in visited[state]:\n",
    "            result = move\n",
    "            break\n",
    "\n",
    "    if result is None:\n",
    "        raise Exception(\"No valid moves available\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def pipe_rotate_binary(board: str, pipe: int):\n",
    "    \"\"\"\n",
    "    Takes a binary representation of a board of pipes as a string, and a pipe to rotate. Outputs a binary representation of the board after rotating the pipe.\n",
    "\n",
    "    :params pipe: The pipe to rotate\n",
    "    :params board: Binary representation of the board as a string\n",
    "\n",
    "    \"\"\"\n",
    "    # each pipe has 4 values associated to it, so pipe n starts at index 4 * n\n",
    "    start_index = 4 * pipe\n",
    "    up = board[start_index]\n",
    "    right = board[start_index + 1]\n",
    "    down = board[start_index + 2]\n",
    "    left = board[start_index + 3]\n",
    "\n",
    "    # rotate clockwise\n",
    "    new_board = (\n",
    "        board[:start_index] + left + up + right + down + board[start_index + 4 :]\n",
    "    )\n",
    "\n",
    "    return new_board\n",
    "\n",
    "\n",
    "def get_bad_pipes(state, goal):\n",
    "    bad = []\n",
    "    # Compare each 4-bit chunk (representing a pipe)\n",
    "    for i in range(0, len(state), 4):\n",
    "        if state[i : i + 4] != goal[i : i + 4]:\n",
    "            bad.append(i // 4)\n",
    "    return bad\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Load puzzles from `puzzles.csv`\n",
    "initials: list[str] = []\n",
    "goals: list[str] = []\n",
    "prev_moves: list[int] = []\n",
    "puzzle_path = os.path.join(curr_dir, \"data/puzzles.csv\")\n",
    "with open(puzzle_path, newline=\"\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    # skip the header\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        initials.append(row[0])\n",
    "        goals.append(row[1])\n",
    "        prev_moves.append(int(row[2]))\n",
    "\n",
    "outlier_threshold = 70\n",
    "\n",
    "corrects = 0\n",
    "bad_pipes_when_incorrect = []\n",
    "all_moves = []\n",
    "extra_moves = []\n",
    "bad_pipes_on_moves = []\n",
    "normal_initials = []\n",
    "normal_goals = []\n",
    "\n",
    "outlier_corrects = 0\n",
    "outlier_bad_pipes_when_incorrect = []\n",
    "outlier_all_moves = []\n",
    "outlier_extra_moves = []\n",
    "outlier_bad_pipes_on_moves = []\n",
    "\n",
    "outlier_initials = []\n",
    "outlier_goals = []\n",
    "\n",
    "for i in range(len(initials)):\n",
    "    initial = initials[i]\n",
    "    goal = goals[i]\n",
    "    visited = {}\n",
    "\n",
    "    state = initial\n",
    "    visited[initial] = set()\n",
    "    cur_puzzle_moves = 0\n",
    "    cur_puzzle_bad_pipes_when_incorrect = []\n",
    "    cur_puzzle_corrects = 0\n",
    "\n",
    "    cur_puzzle_bad_pipes_on_moves = []\n",
    "\n",
    "\n",
    "    while state != goal:\n",
    "        move = pick_move(state, visited)\n",
    "        bad_pipes = get_bad_pipes(state, goal)\n",
    "        cur_puzzle_bad_pipes_on_moves.append(len(bad_pipes))\n",
    "        if move in bad_pipes:\n",
    "            cur_puzzle_corrects += 1\n",
    "        else:\n",
    "            cur_puzzle_bad_pipes_when_incorrect.append(len(bad_pipes))\n",
    "        visited[state].add(move)\n",
    "        state = pipe_rotate_binary(state, move)\n",
    "        cur_puzzle_moves += 1\n",
    "\n",
    "    if len(all_moves)+len(outlier_all_moves) > 0:\n",
    "        percentage_outliers = round(len(outlier_all_moves) / (len(all_moves) + len(outlier_all_moves)) * 100, 2)\n",
    "    else:\n",
    "        percentage_outliers = 0\n",
    "    print(f\"Solution {i+1}: {cur_puzzle_moves} moves. {percentage_outliers}% outliers\")\n",
    "\n",
    "    if cur_puzzle_moves - prev_moves[i] < 0:\n",
    "        raise Exception(\n",
    "            f\"Solution {i+1} has {cur_puzzle_moves} moves, but the minimum number of moves is {prev_moves[i]}\"\n",
    "        )\n",
    "\n",
    "    if cur_puzzle_moves < outlier_threshold:\n",
    "        corrects += cur_puzzle_corrects\n",
    "\n",
    "        all_moves.append(cur_puzzle_moves)\n",
    "        extra_moves.append(cur_puzzle_moves - prev_moves[i])\n",
    "\n",
    "        bad_pipes_on_moves.extend(cur_puzzle_bad_pipes_on_moves)\n",
    "        bad_pipes_when_incorrect.extend(cur_puzzle_bad_pipes_when_incorrect)\n",
    "\n",
    "        normal_initials.append(initial)\n",
    "        normal_goals.append(goal)\n",
    "    else:\n",
    "        outlier_corrects += cur_puzzle_corrects\n",
    "\n",
    "        outlier_all_moves.append(cur_puzzle_moves)\n",
    "        outlier_extra_moves.append(cur_puzzle_moves - prev_moves[i])\n",
    "\n",
    "        outlier_bad_pipes_when_incorrect.extend(cur_puzzle_bad_pipes_when_incorrect)\n",
    "        outlier_bad_pipes_on_moves.extend(cur_puzzle_bad_pipes_on_moves)\n",
    "\n",
    "        outlier_initials.append(initial)\n",
    "        outlier_goals.append(goal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving Statistics\n",
    "\n",
    "Displays statistics on the solving process of all puzzles, this separates statistics between normal puzzles and outlier puzzles for easier comparison. For both normal and outliers, we display the **accuracy**, which is defined as the percentage of moves it makes that were correct.\n",
    "\n",
    "we also display average and median of:\n",
    "- Moves (number of moves it took to solve)\n",
    "- Extra moves (number of extra moves it took to solve compared to the optimal minimal moves required)\n",
    "- Bad pipes after moves (number of pipes that are in incorrect orientations after every move)\n",
    "    - Helps us understand what kind of states the model spends most of its time on\n",
    "- Bad pipes when incorrect (number of pipes that are in incorrect orientations when model makes a mistake)\n",
    "    - Helps us understand what kind of states it's struggling on\n",
    "- Initial bad pipes (number of of pipes that are in incorrect orientations in the beginning)\n",
    "    - Helps us understand how the puzzles are scrambled initially\n",
    "\n",
    "### Graphs on Time Spent on Each State\n",
    "We plot bad pipes after every move for both normal and outlier puzzles to observe its distribution. Despite average/median being similar,\n",
    "the distributions are wildly different.\n",
    "\n",
    "**Normal** bad pipe frequency is skewed towards lower values, suggesting that it's spending most of its time close to completion, which is to be expected as the puzzle gets harder for the network the closer it is to completion.\n",
    "\n",
    "**Outlier** bad pipe frequency is a normal distribution centered roughly in the middle, suggesting that it's not making significant progress and spending most of its time with roughly half the pipes at incorrect orientations.\n",
    "\n",
    "### Graphs for Mistakes on Each State\n",
    "We plot number of bad pipes when it makes it mistake on both normal and outliers. Both are distributed normally.\n",
    "\n",
    "**Normal** mistakes are centered towards 3 bad pipes, although the frequency of mistakes is so low that it's not a real issue.\n",
    "\n",
    "**Outlier** mistakes are centered at 6 and 7, suggesting that it is having a hard time getting out that state where roughly half the pipes are incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "# print percentage that are outliers\n",
    "percentage_outliers = round(len(outlier_all_moves) / (len(all_moves) + len(outlier_all_moves)) * 100, 2)\n",
    "print(f\"{percentage_outliers}% outliers\")\n",
    "print()\n",
    "print(\"--------------------------------\")\n",
    "print(\"NON-OUTLIER RESULTS\")\n",
    "\n",
    "print(f\"Accuracy: {corrects / sum(all_moves)}\")\n",
    "\n",
    "print()\n",
    "print(\"MOVES STATISTICS\")\n",
    "print(f\"Average moves: {sum(all_moves) / len(all_moves)}\")\n",
    "print(f\"Median moves: {sorted(all_moves)[len(all_moves) // 2]}\")\n",
    "print(f\"Average extra moves: {sum(extra_moves) / len(extra_moves)}\")\n",
    "print(f\"Median extra moves: {sorted(extra_moves)[len(extra_moves) // 2]}\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"BAD PIPES STATISTICS\")\n",
    "print(f\"Average bad pipes after moves: {sum(bad_pipes_on_moves) / len(bad_pipes_on_moves)}\")\n",
    "print(f\"Median bad pipes after moves: {sorted(bad_pipes_on_moves)[len(bad_pipes_on_moves) // 2]}\")\n",
    "if len(bad_pipes_when_incorrect) > 0:\n",
    "    print(\n",
    "        f\"Average bad pipes when incorrect: {sum(bad_pipes_when_incorrect) / len(bad_pipes_when_incorrect)}\"\n",
    "    )\n",
    "    print(f\"Median bad pipes when incorrect: {sorted(bad_pipes_when_incorrect)[len(bad_pipes_when_incorrect) // 2]}\")\n",
    "else:\n",
    "    print(\"No incorrect moves on non-outliers!!!\")\n",
    "initial_bad_pipes = [len(get_bad_pipes(normal_initials[i], normal_goals[i])) for i in range(len(normal_initials))]\n",
    "print(f\"Average initial bad pipes: {sum(initial_bad_pipes) / len(initial_bad_pipes)}\")\n",
    "print(f\"Median initial bad pipes: {sorted(initial_bad_pipes)[len(initial_bad_pipes) // 2]}\")\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"--------------------------------\")\n",
    "print(\"OUTLIER RESULTS\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"OUTLIER STATISTICS\")\n",
    "print(f\"{len(outlier_all_moves)} Outliers: {outlier_all_moves}\")\n",
    "print(f\"Max outlier: {max(outlier_all_moves)}\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(f\"Accuracy: {outlier_corrects / sum(outlier_all_moves)}\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"MOVES STATISTICS\")\n",
    "print(f\"Average moves: {sum(outlier_all_moves) / len(outlier_all_moves)}\")\n",
    "print(f\"Median moves: {sorted(outlier_all_moves)[len(outlier_all_moves) // 2]}\")\n",
    "print(f\"Average extra moves: {sum(outlier_extra_moves) / len(outlier_extra_moves)}\")\n",
    "print(f\"Median extra moves: {sorted(outlier_extra_moves)[len(outlier_extra_moves) // 2]}\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"BAD PIPES STATISTICS\")\n",
    "print(f\"Average bad pipes after moves: {sum(outlier_bad_pipes_on_moves) / len(outlier_bad_pipes_on_moves)}\")\n",
    "print(f\"Median bad pipes after moves: {sorted(outlier_bad_pipes_on_moves)[len(outlier_bad_pipes_on_moves) // 2]}\")\n",
    "if len(outlier_bad_pipes_when_incorrect) > 0:\n",
    "    print(\n",
    "        f\"Average bad pipes when incorrect: {sum(outlier_bad_pipes_when_incorrect) / len(outlier_bad_pipes_when_incorrect)}\"\n",
    "    )\n",
    "    print(f\"Median bad pipes when incorrect: {sorted(outlier_bad_pipes_when_incorrect)[len(outlier_bad_pipes_when_incorrect) // 2]}\")\n",
    "else:\n",
    "    print(\"No incorrect moves on outliers!!!\")\n",
    "\n",
    "initial_bad_pipes = [len(get_bad_pipes(outlier_initials[i], outlier_goals[i])) for i in range(len(outlier_initials))]\n",
    "print(f\"Average initial bad pipes: {sum(initial_bad_pipes) / len(initial_bad_pipes)}\")\n",
    "print(f\"Median initial bad pipes: {sorted(initial_bad_pipes)[len(initial_bad_pipes) // 2]}\")\n",
    "\n",
    "\n",
    "array1 = bad_pipes_on_moves\n",
    "array2 = outlier_bad_pipes_on_moves\n",
    "\n",
    "array3 = bad_pipes_when_incorrect\n",
    "array4 = outlier_bad_pipes_when_incorrect\n",
    "\n",
    "# Bin edges â€” combine arrays in each pair for consistent bins\n",
    "bins1 = np.histogram_bin_edges(np.concatenate([array1, array2]), bins='auto')\n",
    "bins2 = np.histogram_bin_edges(np.concatenate([array3, array4]), bins='auto')\n",
    "\n",
    "# Plot both comparison histograms\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 12))\n",
    "\n",
    "# First comparison graph\n",
    "axs[0].hist(array1, bins=bins1, alpha=0.6, edgecolor='black', label='Normal')\n",
    "axs[0].hist(array2, bins=bins1, alpha=0.6, edgecolor='black', label='Outliers')\n",
    "axs[0].set_title(\"Time Spent on Each State\")\n",
    "axs[0].set_xlabel(\"Number of Bad Pipes\")\n",
    "axs[0].set_ylabel(\"Frequency\")\n",
    "axs[0].legend()\n",
    "axs[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Second comparison graph\n",
    "axs[1].hist(array3, bins=bins2, alpha=0.6, edgecolor='black', label='Normal')\n",
    "axs[1].hist(array4, bins=bins2, alpha=0.6, edgecolor='black', label='Outliers')\n",
    "axs[1].set_title(\"Mistakes on Each State\")\n",
    "axs[1].set_xlabel(\"Number of Bad Pipes\")\n",
    "axs[1].set_ylabel(\"Frequency\")\n",
    "axs[1].legend()\n",
    "axs[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AFTER-FINE-TUNING: Re-solving Outlier \n",
    "\n",
    "Re-solves outlier puzzles. This cell is meant to be ran after the model has been fine-tuned on the augmented outlier data.\n",
    "\n",
    "To fine-tune the model on augmented data\n",
    "1. Run the below cell to output the outliers.\n",
    "2. Generate new data with `dl_data.py`\n",
    "3. Run `dl_data.py --aug` to augment the outliers\n",
    "4. Run all cells above FINE-TUNE-ONLY cell except for Training\n",
    "5. Run the FINE_TUNE-ONLY cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_name = \"model.pth\"\n",
    "model.load_state_dict(torch.load(model_file_path, weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "initials: list[str] = []\n",
    "goals: list[str] = []\n",
    "prev_moves: list[int] = []\n",
    "extra_moves: list[int] = []\n",
    "still_outliers: list[tuple[str, str, str, str]] = []\n",
    "\n",
    "\n",
    "puzzle_path = os.path.join(curr_dir, \"data/outliers.csv\")\n",
    "with open(puzzle_path, newline=\"\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    # skip the header\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        initials.append(row[0])\n",
    "        goals.append(row[1])\n",
    "        prev_moves.append(int(row[2]))\n",
    "        extra_moves.append(int(row[3]))\n",
    "\n",
    "outlier_new_corrects = 0\n",
    "outlier_new_all_moves = []\n",
    "\n",
    "for i in range(len(initials)):\n",
    "    initial = initials[i]\n",
    "    goal = goals[i]\n",
    "    visited = {}\n",
    "\n",
    "    state = initial\n",
    "    visited[initial] = set()\n",
    "    cur_puzzle_moves = 0\n",
    "    cur_puzzle_corrects = 0\n",
    "\n",
    "    while state != goal:\n",
    "        move = pick_move(state, visited)\n",
    "        bad_pipes = get_bad_pipes(state, goal)\n",
    "        if move in bad_pipes:\n",
    "            outlier_new_corrects += 1\n",
    "        visited[state].add(move)\n",
    "        state = pipe_rotate_binary(state, move)\n",
    "        cur_puzzle_moves += 1\n",
    "\n",
    "    print(f\"Solution {i+1}: {cur_puzzle_moves} moves\")\n",
    "\n",
    "    if cur_puzzle_moves > 70:\n",
    "        still_outliers.append((str(initial), str(goal), str(cur_puzzle_moves), str(cur_puzzle_moves - (prev_moves[i]-extra_moves[i]))))\n",
    "    outlier_new_all_moves.append(cur_puzzle_moves)\n",
    "    outlier_new_corrects += cur_puzzle_corrects\n",
    "\n",
    "diffs = [outlier_new_all_moves[i] - prev_moves[i] for i in range(len(outlier_new_all_moves))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Outliers\n",
    "\n",
    "Output outliers to `data/outliers.csv`. Storing initial state, goal state, moves it took to solve, and extra moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputting outliers to data/outliers.csv\n",
    "with open(\"data/outliers.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"initial_state\", \"solution_state\", \"moves\", \"extra_moves\"])\n",
    "    for i in range(len(outlier_goals)):\n",
    "        writer.writerow([outlier_initials[i], outlier_goals[i], outlier_all_moves[i], outlier_extra_moves[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics on New Outlier Performance \n",
    "\n",
    "Displays statistics on its new performance on outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {outlier_new_corrects / sum(outlier_new_all_moves)}\")\n",
    "print(f\"Average moves: {sum(outlier_new_all_moves) / len(outlier_new_all_moves)}\")\n",
    "print(f\"Median moves: {sorted(outlier_new_all_moves)[len(outlier_new_all_moves) // 2]}\")\n",
    "print(f\"Diff: {diffs}\")\n",
    "print(f\"Average diff: {sum(diffs) / len(diffs)}\")\n",
    "print(f\"Median diff: {sorted(diffs)[len(diffs) // 2]}\")\n",
    "\n",
    "print(f\"Solved {len(outlier_new_all_moves)-len(still_outliers)}/{len(outlier_new_all_moves)} outliers\")\n",
    "\n",
    "# graph the diffs\n",
    "plt.bar(range(len(diffs)), diffs)\n",
    "\n",
    "# Optional: Add labels and title\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Difference')\n",
    "plt.title('Move Difference of Outlier Puzzles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append Remaining Outliers\n",
    "\n",
    "Appends previous outliers that are still outliers to `outliers.csv`. This cell is meant to be ran after the newly fine-tuned model solved all previous outliers and after we outputted the new outliers found with the newly fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/outliers.csv\", \"a\") as f:\n",
    "    for still_outlier in still_outliers:\n",
    "        f.write(f\"{still_outlier[0]},{still_outlier[1]},{still_outlier[2]},{still_outlier[3]}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
